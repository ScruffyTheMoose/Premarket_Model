{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yahoo_fin.stock_info as si"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that will take the normal price history and output a new dataframe containing the features.\n",
    "\n",
    "The features are the sector of the company being evaluated and the post/pre market price change percentage.\n",
    "The 'day_change' column will be used to generate a label in the completed test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read price data and output new dataframe containing premarket change by date\n",
    "# data to generate/retain:\n",
    "    # overnight change percentage\n",
    "    # following day change percentage\n",
    "def feature_label(historical_prices: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    # length of dataframe and lists\n",
    "    length = historical_prices.shape[0] # num of rows\n",
    "\n",
    "    # list of all opening and closing historical prices\n",
    "    price_open = historical_prices['open'].tolist()\n",
    "    price_close = historical_prices['close'].tolist()\n",
    "\n",
    "    # dataframe that will be returned\n",
    "    result_data = pd.DataFrame(columns=('sector', 'premarket_change', 'day_change'))\n",
    "\n",
    "    company = filename[:-4]\n",
    "\n",
    "    # getting sector of company\n",
    "    sector = si.get_company_info(company).loc['sector']['Value']\n",
    "\n",
    "    # iterating through the lists, determining changes by %, and adding to result DF\n",
    "    # adds sector feature\n",
    "    for i in range(length - 1):\n",
    "        # change in price overnight / previous close price\n",
    "        premarket_change = ( (price_open[i + 1] - price_close[i]) / price_close[i] ) * 100\n",
    "\n",
    "        # change in price during day / opening price of day\n",
    "        day_change = ( (price_close[i + 1] - price_open[i + 1]) / price_open[i + 1] ) * 100\n",
    "\n",
    "        result_data.loc[i] = [sector, premarket_change, day_change]\n",
    "\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling 'feature_label' function on every csv file in the given directory to process and store the new data to the clean_stock_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "for filename in os.listdir('raw_stock_data'):\n",
    "    \n",
    "    # easy tracking of progress because I'm lazy\n",
    "    print(f\"getting data for {filename}... {n}/500\")\n",
    "    n += 1\n",
    "    \n",
    "    data = pd.read_csv(f'raw_stock_data/{filename}')\n",
    "    result = feature_label(data, filename)\n",
    "    result.to_csv(path_or_buf=f\"clean_stock_data/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to identify the appropriate label for each row. This was added afterwards when I realize that this classification model needs class labels. Rather than refactoring the code and data completely, I decided to build this to append the labels more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to determine label to apply to data pair\n",
    "def get_class(row) -> str:\n",
    "    if row['day_change'] < 0:\n",
    "        return 'decrease'\n",
    "    elif row['day_change'] > 0:\n",
    "        return 'increase'\n",
    "    else:\n",
    "        return 'minimal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all the data is concatenated into a single dataframe. This is done in order to fit the model to the complete dataset.\n",
    "\n",
    "We then call the 'get_class' function inside a lambda function to assign the appropraite label to each row in the dataset.\n",
    "\n",
    "Lastly, the completed dataset is stored as a csv for easy read/write access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all cleaned data and concat into a single DataFrame for fitting the model\n",
    "\n",
    "# list to track all referenced to dataframes of stock data\n",
    "df_tracker = []\n",
    "\n",
    "# iterating through directory to pull in all csv files as dataframes and storing references in df_tracker\n",
    "n = 1\n",
    "for filename in os.listdir('clean_stock_data'):\n",
    "    \n",
    "    # easy tracking of progress because I'm lazy part 2 hehe\n",
    "    print(f\"parsing data from {filename} to features and labels... {n}/500\")\n",
    "    n += 1\n",
    "\n",
    "    try:\n",
    "        data = pd.read_csv(f'clean_stock_data/{filename}')\n",
    "        df_tracker.append(data)\n",
    "    except:\n",
    "        print(f\"Failed to copy data from {filename} to full_df...\")\n",
    "\n",
    "# concatenating all the data into a single set\n",
    "full_df = pd.concat(df_tracker, ignore_index=True)\n",
    "\n",
    "# adding label to each row\n",
    "full_df['label'] = full_df.apply(lambda row: get_class(row), axis=1)\n",
    "\n",
    "# exporting complete dataset to csv\n",
    "full_df.to_csv(path_or_buf='complete_datasets/complete_stock_ds.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
